{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 3g --driver-memory 2g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy. linalg import norm\n",
    "conf = SparkConf()\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(conf=conf)\\\n",
    "    .appName(\"GF_spark\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GF_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f525a98cbe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GF_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=GF_spark>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs  655090069 2022-01-06 18:46 /labs/slaba04/gender_age_dataset.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /labs/slaba04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('gender').count().rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/labs/slaba04/gender_age_dataset.txt', sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CAST(1 AS TINYINT): byte (nullable = false)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.lit(1).cast(t.ByteType()), 'gender').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " gender    | F                    \n",
      " age       | 18-24                \n",
      " uid       | d50192e5-c44e-4ae... \n",
      " user_json | {\"visits\": [{\"url... \n",
      "-RECORD 1-------------------------\n",
      " gender    | M                    \n",
      " age       | 25-34                \n",
      " uid       | d502331d-621e-472... \n",
      " user_json | {\"visits\": [{\"url... \n",
      "-RECORD 2-------------------------\n",
      " gender    | F                    \n",
      " age       | 25-34                \n",
      " uid       | d50237ea-747e-48a... \n",
      " user_json | {\"visits\": [{\"url... \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- user_json: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|     F|\n",
      "|     M|\n",
      "|     -|\n",
      "+------+\n",
      "\n",
      "+-----+\n",
      "|  age|\n",
      "+-----+\n",
      "| >=55|\n",
      "|45-54|\n",
      "|    -|\n",
      "|35-44|\n",
      "|25-34|\n",
      "|18-24|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('gender').distinct().show()\n",
    "df.select('age').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((F.col('age') != '-') & (F.col('gender') != '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|     F|\n",
      "|     M|\n",
      "+------+\n",
      "\n",
      "+-----+\n",
      "|  age|\n",
      "+-----+\n",
      "| >=55|\n",
      "|45-54|\n",
      "|35-44|\n",
      "|25-34|\n",
      "|18-24|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('gender').distinct().show()\n",
    "df.select('age').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def www(x):\n",
    "    l = []\n",
    "    x = json.loads(x)['visits']\n",
    "    for i in x:\n",
    "        a = i['url'].strip()\n",
    "        b = re.search(\"(?:http[s]?:\\/\\/)+(?:www\\.)?([^\\/]*)\",a)\n",
    "        if b:\n",
    "            l.append(b.group(1))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n = df.rdd.map(lambda x: (x[0], x[1])).distinct().map(lambda x: ([x[0], x[1]])).collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "di = {}\n",
    "temp = 0\n",
    "for i in list_n:\n",
    "    di[temp] = i\n",
    "    temp +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_1 = {0: \"M\", 1: 'F'}\n",
    "di_2 = {0: '18-24', 1: '25-34',2: '35-44' ,3: '45-54', 4: '>=55'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_a(x):\n",
    "    for i in di_2:\n",
    "        if x == di_2[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_s(x):\n",
    "    for i in di_1:\n",
    "        if x == di_1[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+\n",
      "|gender|  age|                 uid|           user_json|\n",
      "+------+-----+--------------------+--------------------+\n",
      "|     F|18-24|d50192e5-c44e-4ae...|{\"visits\": [{\"url...|\n",
      "|     M|25-34|d502331d-621e-472...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d50237ea-747e-48a...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d502f29f-d57a-46b...|{\"visits\": [{\"url...|\n",
      "|     M| >=55|d503c3b2-a0c2-4f4...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d5090ddf-5648-487...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d50bcef8-16ff-4e8...|{\"visits\": [{\"url...|\n",
      "|     F|18-24|d50e23dc-0cbd-488...|{\"visits\": [{\"url...|\n",
      "|     F|45-54|d50fdabb-4208-441...|{\"visits\": [{\"url...|\n",
      "|     F|18-24|d511b480-23a6-482...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d51294ed-1b95-4e4...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d512e295-6a85-491...|{\"visits\": [{\"url...|\n",
      "|     M|25-34|d51441ea-9dda-454...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d51822d4-105b-457...|{\"visits\": [{\"url...|\n",
      "|     F|35-44|d5183db2-c8e5-413...|{\"visits\": [{\"url...|\n",
      "|     M|35-44|d51974e3-19c5-46d...|{\"visits\": [{\"url...|\n",
      "|     M|25-34|d51cba2e-f666-46d...|{\"visits\": [{\"url...|\n",
      "|     F|18-24|d51dd42c-3b36-4a6...|{\"visits\": [{\"url...|\n",
      "|     F|35-44|d51fdc5e-8eae-4bb...|{\"visits\": [{\"url...|\n",
      "|     F| >=55|d522c18e-e38a-4b7...|{\"visits\": [{\"url...|\n",
      "+------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.rdd.map(lambda x: (g_s(x[0]), g_a(x[1]), x[2], www(x[3])))\n",
    "\n",
    "schema = t.StructType(fields=[t.StructField(\"gender\", t.IntegerType()),\n",
    "                            t.StructField(\"age\", t.IntegerType()),\n",
    "                            t.StructField(\"uid\", t.StringType()),\n",
    "                             t.StructField(\"fff\", t.ArrayType(t.StringType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  0,\n",
       "  'd50192e5-c44e-4ae8-ae7a-7cfe67c8b777',\n",
       "  ['zebra-zoya.ru',\n",
       "   'news.yandex.ru',\n",
       "   'sotovik.ru',\n",
       "   'news.yandex.ru',\n",
       "   'sotovik.ru'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- fff: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+------+---+--------------------+--------------------+\n",
      "|gender|age|                 uid|                 fff|\n",
      "+------+---+--------------------+--------------------+\n",
      "|     1|  0|d50192e5-c44e-4ae...|[zebra-zoya.ru, n...|\n",
      "|     0|  1|d502331d-621e-472...|[sweetrading.ru, ...|\n",
      "|     1|  1|d50237ea-747e-48a...|[ru.oriflame.com,...|\n",
      "|     1|  1|d502f29f-d57a-46b...|[translate-tattoo...|\n",
      "|     0|  4|d503c3b2-a0c2-4f4...|[mail.rambler.ru,...|\n",
      "+------+---+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pre = spark.createDataFrame(rdd, schema=schema)\n",
    "df_pre.printSchema()\n",
    "df_pre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "hashingTF = HashingTF(inputCol = 'fff', outputCol = 'features')\n",
    "output = hashingTF.transform(df_pre)\n",
    "#idf = IDF(inputCol='features_2', outputCol='features')\n",
    "#idfModel = idf.fit(output)\n",
    "#output = idfModel.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#lr_gender = LogisticRegression(featuresCol='features',labelCol='gender',maxIter=15, regParam=2.2)\n",
    "#lr_age = LogisticRegression(featuresCol='features',labelCol='age',maxIter=15, regParam=2.2)\n",
    "lr_gender = RandomForestClassifier(featuresCol='features',labelCol='gender')\n",
    "lr_age = RandomForestClassifier(featuresCol='features',labelCol='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.classification import RandomForestClassifier\n",
    "#lr_gender = RandomForestClassifier(numTrees=5, maxDepth=8, labelCol=\"gender\", seed=42, featuresCol=\"features\")\n",
    "#lr_age = RandomForestClassifier(numTrees=5, maxDepth=8, labelCol=\"age\", seed=42, featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.1 ms, sys: 45.8 ms, total: 90.9 ms\n",
      "Wall time: 4min 27s\n",
      "CPU times: user 61.9 ms, sys: 19.2 ms, total: 81.1 ms\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "#%time train, test = output.randomSplit([0.9, 0.1])\n",
    "%time model_gender = lr_gender.fit(output)\n",
    "%time model_age = lr_age.fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.RandomForestClassificationModel"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model_gender.transform(test).select('gender', 'age', 'features',F.col('prediction').alias('prediction_gender'))\n",
    "#predictions = model_age.transform(predictions)\\\n",
    "#    .select('gender', 'age', F.col('prediction_gender'), F.col('prediction').alias('prediction_age'))\n",
    "#predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.filter((F.col('gender') == F.col('prediction_gender'))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.filter((F.col('age') == F.col('prediction_age'))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aa = predictions.filter((F.col('age') == F.col('prediction_age')) & (F.col('gender') == F.col('prediction_gender'))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb = predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2631578947368421"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aa / bb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15 - 0.26415891800507185\n",
    "30 - 0.2603896988690557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/sergey.vaschuk\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVER = 'spark-node-1.newprolab.com:6667'\n",
    "KAFKA_INPUT_TOPIC = 'input_sergey.vaschuk'\n",
    "KAFKA_OUTPUT_TOPIC = 'sergey.vaschuk'\n",
    "\n",
    "def create_console_sink(df):\n",
    "    return df \\\n",
    "            .writeStream \\\n",
    "            .format(\"console\") \\\n",
    "            .trigger(processingTime=\"10 seconds\") \\\n",
    "            .option(\"truncate\", \"false\")\n",
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_sergey.vaschuk\",\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "\n",
    "def clean_df(df):\n",
    "    event_schema = t.StructType([\n",
    "        t.StructField('uid', t.StringType(), True),\n",
    "        t.StructField('visits', t.StringType(), True),\n",
    "    ])\n",
    "\n",
    "\n",
    "    visit_schema = t.ArrayType(\n",
    "        t.StructType([\n",
    "            t.StructField('url', t.StringType(), True),\n",
    "            #t.StructField('timestamp', t.LongType(), True)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .select(F.col('value').cast('string').alias('value'))\n",
    "        .select(F.from_json(F.col('value'), event_schema).alias('event'))\n",
    "        .select(\n",
    "            'event.uid', \n",
    "            F.from_json(F.col('event.visits'), visit_schema).alias('visits')\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    if streams:\n",
    "        for s in streams:\n",
    "            desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "            s.stop()\n",
    "            print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped KafkaV2[Subscribe[input_sergey.vaschuk]]\n"
     ]
    }
   ],
   "source": [
    "kill_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO GO GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_stream = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "    #.option('startingOffsets', 'earliest')\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kafka_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_stream = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "    #.option('startingOffsets', 'earliest')\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    ")\n",
    "\n",
    "\n",
    "df = clean_df(kafka_stream).withColumn('url', F.col('visits').getItem('url')).select('uid', F.explode('url').alias('url'))\\\n",
    "    .withColumn('url_host', F.expr(\"parse_url(url, 'HOST')\"))\\\n",
    "    .groupBy('uid').agg(F.collect_list('url_host').alias('visits'))\n",
    "\n",
    "hashingTF = HashingTF(inputCol = 'visits', outputCol = 'features')\n",
    "output = hashingTF.transform(df)\n",
    "\n",
    "predictions = model_age.transform(output).select('uid', 'features', F.col('prediction').alias('prediction_age'))\n",
    "predictions = model_gender.transform(predictions).select('uid', F.col('prediction').alias('prediction_gender'), 'prediction_age')\n",
    "predictions_df = predictions.withColumn('gender', F.when(F.col('prediction_gender').isin(0), 'M').otherwise('F'))\\\n",
    "    .withColumn('age', F.when(F.col('prediction_age').isin(0), '18-24')\\\n",
    "               .when(F.col('prediction_age').isin(1), '25-34')\\\n",
    "               .when(F.col('prediction_age').isin(2), '35-44')\\\n",
    "               .when(F.col('prediction_age').isin(3), '45-54')\\\n",
    "               .when(F.col('prediction_age').isin(4), '>=55'))\\\n",
    "    .select('uid', 'gender', 'age')\n",
    "\n",
    "kafka_out_df = (\n",
    "    predictions_df\n",
    "    .select(F.to_json(F.struct(*predictions_df.columns)).alias('value'))\n",
    ")\n",
    "\n",
    "kafka_write_stream = (\n",
    "    kafka_out_df\n",
    "    .writeStream\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .outputMode(\"complete\")\n",
    "    .option(\"checkpointLocation\", \"checkpoints/checkpoints_lab04\")\n",
    "    .option('topic', KAFKA_OUTPUT_TOPIC)\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# батч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_read_df = (\n",
    "    spark.read\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "  #  .option('startingOffsets', \"latest\")\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    "    #.cache()\n",
    ")\n",
    "\n",
    "#test_df = spark.read.parquet('/user/sergey.vaschuk/lab_TEST/')\n",
    "df = clean_df(kafka_read_df).withColumn('url', F.col('visits').getItem('url')).select('uid', F.explode('url').alias('url'))\\\n",
    "    .withColumn('url_host', F.expr(\"parse_url(url, 'HOST')\"))\\\n",
    "    .groupBy('uid').agg(F.collect_list('url_host').alias('visits'))\n",
    "\n",
    "hashingTF = HashingTF(inputCol = 'visits', outputCol = 'features')\n",
    "output = hashingTF.transform(df)\n",
    "#idf = IDF(inputCol='features_2', outputCol='features')\n",
    "#idfModel = idf.fit(output)\n",
    "#output = idfModel.transform(output)\n",
    "\n",
    "predictions = model_age.transform(output).select('uid', 'features', F.col('prediction').alias('prediction_age'))\n",
    "predictions = model_gender.transform(predictions).select('uid', F.col('prediction').alias('prediction_gender'), 'prediction_age')\n",
    "predictions_df = predictions.withColumn('gender', F.when(F.col('prediction_gender').isin(0), 'M').otherwise('F'))\\\n",
    "    .withColumn('age', F.when(F.col('prediction_age').isin(0), '18-24')\\\n",
    "               .when(F.col('prediction_age').isin(1), '25-34')\\\n",
    "               .when(F.col('prediction_age').isin(2), '35-44')\\\n",
    "               .when(F.col('prediction_age').isin(3), '45-54')\\\n",
    "               .when(F.col('prediction_age').isin(4), '>=55'))\\\n",
    "    .select('uid', 'gender', 'age')\n",
    "\n",
    "kafka_out_df = (\n",
    "    predictions_df\n",
    "    .select(F.to_json(F.struct(*predictions_df.columns)).alias('value'))\n",
    ")\n",
    "(\n",
    "    kafka_out_df\n",
    "    .write\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('topic', KAFKA_OUTPUT_TOPIC)\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+\n",
      "|                 uid|gender|  age|\n",
      "+--------------------+------+-----+\n",
      "|0108d217-e476-493...|     F|35-44|\n",
      "|0192cc54-559c-4c8...|     M|45-54|\n",
      "|019acd5e-be9a-4cd...|     F|18-24|\n",
      "|02e7f830-da57-4d5...|     F|35-44|\n",
      "|1d160259-73d8-451...|     F|25-34|\n",
      "|1e14a504-276e-448...|     F|18-24|\n",
      "|1eb313db-34ff-4bf...|     M|25-34|\n",
      "|1eff6e4f-3b8a-447...|     M|25-34|\n",
      "|3e75c432-cb78-488...|     M|35-44|\n",
      "|47565df3-13e3-460...|     M|25-34|\n",
      "|4766a8ab-e9b6-4e0...|     F|35-44|\n",
      "|50637c81-fffa-4ee...|     F|25-34|\n",
      "|5a023519-f28e-4eb...|     M|25-34|\n",
      "|5a781caa-6131-4d9...|     F|25-34|\n",
      "|5ab3c7b8-c550-493...|     F|35-44|\n",
      "|7302e78a-ec04-47e...|     F|18-24|\n",
      "|73081df3-8f41-435...|     F|25-34|\n",
      "|89fe85cb-ea4c-4be...|     M|25-34|\n",
      "|8affa6ce-24c7-4ed...|     M| >=55|\n",
      "|b2e4450d-c582-441...|     F|35-44|\n",
      "+--------------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 11.4 ms, sys: 912 µs, total: 12.3 ms\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%time predictions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
